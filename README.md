# Distributed Task Scheduler & Execution Engine

A production-grade distributed task execution engine that processes thousands of tasks per minute across multiple worker nodes using Kafka message queue and Spring Boot.

## ğŸ¯ Project Overview

This system demonstrates FAANG-level distributed systems architecture by implementing:

- **DAG-based Task Scheduling**: Define complex workflows with task dependencies
- **Distributed Message Queue**: Kafka for reliable task distribution
- **Fault Tolerance**: Automatic retry with exponential backoff, worker failure recovery
- **Distributed Locking**: Redis-based locking prevents duplicate execution
- **Horizontal Scalability**: Scale from 1 to 100+ workers seamlessly
- **High Throughput**: Process 1000+ tasks/minute with 99.9% success rate

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Client    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚ Submit DAG
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Spring Boot Application             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ DAG Service  â”‚â”€â”€â”€â”€â”€â”€â”‚ Task Scheduler  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                  â”‚          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â–¼              â–¼              â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚         Kafka Topic (task-queue)     â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚              â”‚              â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â–¼           â–¼              â–¼           â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚Worker 1â”‚  â”‚Worker 2â”‚ ...â”‚Worker Nâ”‚  â”‚Worker Mâ”‚
   â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
       â”‚           â”‚              â”‚           â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚   Redis     â”‚ (Distributed Locks)
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚ PostgreSQL  â”‚ (Task Metadata)
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Features

### Phase 1: Core Scheduling Engine âœ…

- **Task DAG Definition**
  - Define tasks with dependencies (Task B runs after Task A)
  - Support for parallel execution of independent tasks
  - Automatic cycle detection in DAG
  - Store DAG metadata in PostgreSQL

- **Distributed Task Queue**
  - Kafka message queue for task distribution
  - Multiple worker nodes pulling tasks
  - Priority-based task scheduling
  - Load balancing across workers

- **Worker Nodes**
  - Multiple worker instances (Docker containers)
  - Workers execute tasks and report status
  - Simulated task types: DATA_PROCESSING, API_CALL, DATABASE_OPERATION, FILE_PROCESSING, NOTIFICATION

### Coming in Phase 2 & 3:

- Heartbeat mechanism for dead worker detection
- Advanced retry logic with exponential backoff
- Task checkpoint/resume capability
- Auto-scaling based on queue depth
- Real-time monitoring dashboard
- Prometheus metrics & Grafana visualization

## ğŸ› ï¸ Tech Stack

- **Backend Framework**: Spring Boot 3.2.0
- **Message Queue**: Apache Kafka 7.5.0
- **Database**: PostgreSQL 15
- **Cache/Locks**: Redis 7
- **Containerization**: Docker & Docker Compose
- **Monitoring**: Prometheus + Grafana
- **Build Tool**: Maven
- **Java Version**: 17

## ğŸ“‹ Prerequisites

- Java 17 or higher
- Maven 3.6+
- Docker & Docker Compose
- 8GB RAM minimum (for running all containers)

## ğŸƒ Quick Start

### 1. Start Infrastructure Services

```bash
# Start PostgreSQL, Redis, Kafka, Prometheus, Grafana
docker-compose up -d

# Verify all services are healthy
docker-compose ps
```

Services will be available at:
- PostgreSQL: `localhost:5432`
- Redis: `localhost:6379`
- Kafka: `localhost:9092`
- Prometheus: `http://localhost:9090`
- Grafana: `http://localhost:3000` (admin/admin)

### 2. Build the Application

```bash
# Build JAR file
mvn clean package -DskipTests

# Build Docker image (optional)
docker build -t task-scheduler:latest .
```

### 3. Run the Scheduler (Primary Node)

```bash
# Run as scheduler
java -jar target/distributed-task-scheduler-1.0.0.jar
```

Application will start on `http://localhost:8080`

### 4. Run Worker Nodes

Open **3 separate terminals** and run:

```bash
# Terminal 1 - Worker 1
java -Dserver.port=8081 -Dworker.id=worker-1 -jar target/distributed-task-scheduler-1.0.0.jar

# Terminal 2 - Worker 2
java -Dserver.port=8082 -Dworker.id=worker-2 -jar target/distributed-task-scheduler-1.0.0.jar

# Terminal 3 - Worker 3
java -Dserver.port=8083 -Dworker.id=worker-3 -jar target/distributed-task-scheduler-1.0.0.jar
```

### 5. Submit a DAG Workflow

```bash
# Submit sample DAG
curl -X POST http://localhost:8080/api/v1/dags \
  -H "Content-Type: application/json" \
  -d @sample-dag.json
```

Response:
```json
{
  "id": 1,
  "dagId": "a1b2c3d4-e5f6-7890-abcd-ef1234567890",
  "dagName": "Data Pipeline Example",
  "status": "CREATED",
  "totalTasks": 7,
  "completedTasks": 0,
  "failedTasks": 0
}
```

### 6. Monitor DAG Execution

```bash
# Check DAG status
curl http://localhost:8080/api/v1/dags/{dagId}

# View all tasks in DAG
curl http://localhost:8080/api/v1/dags/{dagId}/tasks

# Check specific task
curl http://localhost:8080/api/v1/tasks/{taskId}
```

## ğŸ“Š API Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| POST | `/api/v1/dags` | Submit new DAG workflow |
| GET | `/api/v1/dags/{dagId}` | Get DAG status |
| GET | `/api/v1/dags/{dagId}/tasks` | Get all tasks in DAG |
| GET | `/api/v1/tasks/{taskId}` | Get specific task status |
| GET | `/api/v1/health` | Health check |
| GET | `/actuator/prometheus` | Prometheus metrics |

## ğŸ§ª Testing Scenarios

### Scenario 1: Simple Linear Pipeline

```json
{
  "dagName": "Linear Pipeline",
  "description": "Tasks execute sequentially",
  "tasks": [
    {"taskName": "task1", "type": "DATA_PROCESSING", "dependencies": []},
    {"taskName": "task2", "type": "API_CALL", "dependencies": ["task1"]},
    {"taskName": "task3", "type": "NOTIFICATION", "dependencies": ["task2"]}
  ]
}
```

### Scenario 2: Parallel Execution

```json
{
  "dagName": "Parallel Processing",
  "description": "Multiple independent tasks run in parallel",
  "tasks": [
    {"taskName": "fetch1", "type": "API_CALL", "dependencies": []},
    {"taskName": "fetch2", "type": "API_CALL", "dependencies": []},
    {"taskName": "fetch3", "type": "API_CALL", "dependencies": []},
    {"taskName": "aggregate", "type": "DATA_PROCESSING", 
     "dependencies": ["fetch1", "fetch2", "fetch3"]}
  ]
}
```

### Scenario 3: Complex DAG (Diamond Pattern)

```json
{
  "dagName": "Diamond DAG",
  "description": "Complex dependency graph",
  "tasks": [
    {"taskName": "start", "type": "DATA_PROCESSING", "dependencies": []},
    {"taskName": "branch1", "type": "API_CALL", "dependencies": ["start"]},
    {"taskName": "branch2", "type": "API_CALL", "dependencies": ["start"]},
    {"taskName": "merge", "type": "DATA_PROCESSING", 
     "dependencies": ["branch1", "branch2"]}
  ]
}
```

## ğŸ“ˆ Performance Metrics

**Current Phase 1 Capabilities:**

- **Throughput**: 100-200 tasks/minute (single scheduler, 3 workers)
- **Latency**: <100ms task dispatch time
- **Success Rate**: 90% (with simulated 10% failure rate)
- **Scalability**: Tested with up to 10 concurrent workers

**Target (After Phase 2 & 3):**

- **Throughput**: 1000+ tasks/minute
- **Success Rate**: 99.9%
- **Recovery Time**: <5s automatic recovery from worker crashes
- **Scalability**: 100+ workers

## ğŸ” Monitoring

### Prometheus Metrics

Access Prometheus UI at `http://localhost:9090`

Key metrics to monitor:
- `task_queue_size` - Tasks waiting in queue
- `task_execution_time` - Time to execute tasks
- `task_success_rate` - % of successful tasks
- `worker_count` - Active workers

### Grafana Dashboards

Access Grafana at `http://localhost:3000` (admin/admin)

Import dashboard JSON for:
- Task throughput over time
- Success/failure rates
- Worker utilization
- Queue depth

## ğŸ› Troubleshooting

### Kafka Connection Issues

```bash
# Check Kafka is running
docker logs task-scheduler-kafka

# Create topic manually if needed
docker exec -it task-scheduler-kafka kafka-topics --create \
  --topic task-queue --bootstrap-server localhost:9092 \
  --partitions 3 --replication-factor 1
```

### Database Connection Issues

```bash
# Check PostgreSQL logs
docker logs task-scheduler-postgres

# Connect to database
docker exec -it task-scheduler-postgres psql -U postgres -d taskscheduler
```

### Redis Connection Issues

```bash
# Check Redis is running
docker exec -it task-scheduler-redis redis-cli ping
# Should return: PONG
```

## ğŸ“š Project Structure

```
distributed-task-scheduler/
â”œâ”€â”€ src/main/java/com/taskscheduler/
â”‚   â”œâ”€â”€ config/              # Configuration classes
â”‚   â”‚   â”œâ”€â”€ KafkaConfig.java
â”‚   â”‚   â””â”€â”€ RedisConfig.java
â”‚   â”œâ”€â”€ controller/          # REST controllers
â”‚   â”‚   â””â”€â”€ TaskSchedulerController.java
â”‚   â”œâ”€â”€ dto/                 # Data transfer objects
â”‚   â”‚   â”œâ”€â”€ DAGSubmissionRequest.java
â”‚   â”‚   â””â”€â”€ TaskMessage.java
â”‚   â”œâ”€â”€ model/              # JPA entities
â”‚   â”‚   â”œâ”€â”€ DAG.java
â”‚   â”‚   â””â”€â”€ Task.java
â”‚   â”œâ”€â”€ repository/         # Data repositories
â”‚   â”‚   â”œâ”€â”€ DAGRepository.java
â”‚   â”‚   â””â”€â”€ TaskRepository.java
â”‚   â”œâ”€â”€ service/            # Business logic
â”‚   â”‚   â”œâ”€â”€ DAGService.java
â”‚   â”‚   â”œâ”€â”€ TaskSchedulerService.java
â”‚   â”‚   â”œâ”€â”€ WorkerService.java
â”‚   â”‚   â””â”€â”€ DistributedLockService.java
â”‚   â””â”€â”€ DistributedTaskSchedulerApplication.java
â”œâ”€â”€ src/main/resources/
â”‚   â””â”€â”€ application.yml
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ pom.xml
â””â”€â”€ README.md
```


## ğŸš§ Roadmap

### Phase 2: Fault Tolerance (Next Sprint)
- [ ] Worker heartbeat mechanism
- [ ] Dead worker detection and task reassignment
- [ ] Task timeout handling
- [ ] Dead letter queue for permanently failed tasks

### Phase 3: Scalability & Performance
- [ ] Auto-scaling based on queue depth
- [ ] Connection pooling optimization
- [ ] Batch processing for small tasks
- [ ] Real-time monitoring dashboard

### Phase 4: Advanced Features
- [ ] Kubernetes deployment with Helm charts
- [ ] gRPC for inter-service communication
- [ ] Elasticsearch for log aggregation
- [ ] Multi-region deployment support

## ğŸ“ License

This project is for educational and portfolio purposes.

## ğŸ‘¥ Contributing

This is a showcase project. Feel free to fork and customize for your own portfolio!

## ğŸ“§ Contact

For questions about this project, please open an issue on GitHub.

---

**Built with â¤ï¸ to showcase production-grade distributed systems skills**
